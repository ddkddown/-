# 虚拟化

## 进程

非正式地对进程进行定义非常简单：进程就是一个正在执行的程序。程序是磁盘上的一堆代表着程序指令的存储在磁盘上的文本文件，等待着被操作。

**问题： 操作系统是如何制造存在多个CPU的幻象呢？即使当前只有很少的CPU核，操作系统是如何创造了一种有用之不竭的CPU核的幻象呢？**

答案：操作系统通过对CPU的虚拟化完成。通过执行一个进程一段时间，然后停止，接着去执行另一个进程，如此往复，操作系统就创造了一种有很多CPU核的幻象。这其中的技术是CPU划分时间片。潜在的开销是会使程序运行得更慢一些。

#### 进程API

如今的任何一个现代操作系统都需要以某种形式提供以下API

- 创建：一个操作系统必须包含某些方法去创建新的进程。当我们在shell中敲入命令或者双击某个应用图标，操作系统都需要去创建一个新进程去执行这些程序。
- 销毁：有创建就有销毁，操作系统也提供接口去强制销毁进程。当然，某些进程会自动运行结束退出，单如果进程不这样做的时候，就需要操作系统有这样的接口提供给用户去杀死进程。
- 等待：有时候进程需要停止运行，同样就需要操作系统提供接口。
- 其余控制：处理杀死等待创建，操作系统也还需要提供其他的接口。例如提供接口让程序挂起，然后再进行恢复。
- 状态：同样，需要操作系统提供接口以获取一个进程的状态，例如运行时长，运行状态。

#### 创建进程的细节

​	操作系统是如何让程序运行起来的呢？创建程序的过程是怎样的呢？

​	首先，程序最初是以一种可执行的格式存放在磁盘上，操作系统需要读取磁盘上程序的这些字节，加载程序的代码和静态数据（比如:已初始化的变量）到内存里程序的地址空间中。

 在早期操作系统中，在运行程序很早之前会一次性将程序全部内容加载到内存里。而现代操作要懒一些，当它们运行程序时只会加载运行时需要的那一部分内容到内存里。

到程序的代码和数据被加载到内存里后，操作系统还需要做一些事情来让程序运行起来：

- 需要分配一些内存空间作为程序的栈空间，而传入main函数的参数argc和argv就是初始化在栈空间上的。
- 需要分配一些内存空间作为程序的堆空间，并且随着程序运行对malloc的显式调用，堆空间会不断增大。
- 关联IO，例如，在unix操作系统中，每个进程都默认拥有三个打开的文件描述符：标准输入、标准输出、标准错误输出。
- 通过程序入口main函数运行程序，并且操作系统转交CPU的控制权给新创建的进程，进程就可以开始运行了。

#### 进程状态

​	简而言之，进程拥有三个状态：

- 运行：处于这个状态的进程，正在一个处理器上运行，处理器上正在执行代码指令。

- 就绪：处于这个状态的进程，已经准备好运行，但出于某些原因，操作系统当前不会运行它。

- 阻塞：处于这个状态的进程，通常因为它需要请求某些操作或资源导致目前不能继续运行，直到它的请求完成。最通俗的例子：当一个进程在磁盘上发起一个IO请求时，它的状态就变为阻塞，并且处理器也被移交给其他进程。

  

![批注 2020-09-02 092012](C:\Users\Administrator\Desktop\批注 2020-09-02 092012.png)

#### 数据结构

​	为了跟踪每个进程的状态信息，操作系统会为所有进程保存一个进程列表提供一些信息来跟踪哪些进程是处于运行态的。同样，对于阻塞状态的进程，操作系统也要维持一个进程列表来跟踪。

下图展示了一些操作系统需要跟踪一个进程的信息。<img src="C:\Users\Administrator\Desktop\批注 2020-09-02 094330.png" alt="批注 2020-09-02 094330" style="zoom:75%;" />

当一个进程被停止后，它的寄存器值会被保存到内存中，这样的话，操作系统才能在之后回复程序的运行，这就是上下文切换。除了就绪、运行、阻塞之外，有时候进程还会有初始化状态和终止状态（已经结束但还未被清理，在UNIX上也叫僵尸状态），终止状态可以让父进程去检查刚结束的进程是否执行正确（例如，在unix系统上执行结束返回结果为0），父进程会执行wait调用等待子进程的完成，然后通知操作系统可以对子进程的相关数据结构进行清理。



## 机制：限制直接执行

​	为了实现CPU虚拟化，操作系统需要以某种方式让多个任务在同一时间共享物理CPU。核心的观念很简单：运行一个进程一段时间，然后运行另一个。通过时间片共享就实现了CPU虚拟化。

操作系统必须在掌握整个系统控制的情况下去最大化实现CPU虚拟化，因此硬件和操作系统的支持都很重要。操作系统会经常需要硬件的支持去更高效地实现虚拟化。

#### 问题1： 限制操作

直接运行进程比较快是因为其有很明显的优势：进程直接跑在物理硬件CPU上。但着会引发一个问题：如果进程想做一些受限制的操作，比如磁盘IO请求或者对其他系统资源的获取时，该怎么办呢？

（如果进程操作不受限制的话，那么其中会发生的一种情况就是：它会写满磁盘，破坏系统。）

难点在于：进程必须有某种方式进行IO或者其他受限制的操作，但是同时也不能给进程完全掌控系统的权力，这就需要操作系统和硬件以某种方式协作来提供。

因为便提出了一个新的处理器模式-----用户态，跑在用户态的程序是受限制的，例如不能发出IO请求，不然处理器就会抛出异常然后杀死进程。与用户态形成对比的是内核态，这是操作系统（或者说内核）所处的处理器模式，在这个模式下。程序是不受限制的，可以做任何操作。

那么还有个问题：当一个用户态进程想做一些受限制的操作时该怎么办呢？几乎所有的现代硬件都提供了让用户进程进行系统调用的能力。系统调用允许内核暴露一些关键部分的功能调用给用户进程。

（硬件设备通过提供不同的执行模式来帮助操作系统，在用户态，应用不拥有全部的硬件资源权限，在内核态，操作系统可以操作所有的硬件资源。同时也提供了特殊指令可以让用户态陷入内核态（同时保存用户态的上下文信息），然后再从内核态返回用户态（安装之前保存的上下文信息继续运行），以及一些指令让操作系统告诉硬件系统调用表（内核在启动的时候也建立一个系统调用表）在内存中的位置。）

#### 问题2：进程间切换

​	第二个关于直接运行的问题是在进程间切换，通过一个时间设备经过编码后在每个定时抛出硬件中断，并将当前运行的程序挂起，然后调用一个在操作系统中事先配置好的中断处理，这时操作系统就获取了CPU的控制权，停止当前进程，运行另一个进程。

​	

#### 上下文切换

上下文切换的概念很简单：操作系统需要将当前运行进程的寄存器的值进程保存，然后将即将运行进程的寄存器的值恢复。当发生时间中断时，寄存器的值是由硬件隐式存储的，而当操作系统主动执行进程切换时，寄存器的值是由软件显示存储的。

当操作系统正在处理一个中断时是屏蔽中断的，当然屏蔽中断过长时间也会导致失去中断。现代操作系统发展出许多复杂的锁系统来保护并行数据，这也促使内核中能同时进行很多活动，在多处理器上会很有用。



## 调度器

#### 调度指标

周转时间：周转时间是一个任务的完成时间减去任务的到达时间得到的时间差值。

公平性

#### FIFO

假定队列为A-B-C三个任务**同时到达**排列，在单核上依次运行 ，A任务在10s完成，然后运行B，B任务在20s完成，然后运行C，C任务在30s完成，那么平均周转时间为（10+20+30）/ 3 = 20。

![批注 2020-09-03 102112](C:\Users\Administrator\Desktop\批注 2020-09-03 102112.png)

但是对于FIFO结构，如果A，B，C三个任务的运行时间不同，就会造成周转时间不必要地拉长。

![批注 2020-09-03 102512](C:\Users\Administrator\Desktop\批注 2020-09-03 102512.png)

（100+110+120）/ 3 = 110

#### 短任务优先SJF

**同时到达**优先执行耗时短的任务，耗时长的任务排在后面。

![批注 2020-09-03 103049](C:\Users\Administrator\Desktop\批注 2020-09-03 103049.png)

(10+20+120)/3=50

SJF的问题在于，如果有任务依次到达，那么短任务还是需要等待长任务完成后再进行。例如A任务在0时到达，需要运行100s，b和c任务在10s时同时到达，需要运行10s。

![批注 2020-09-03 104022](C:\Users\Administrator\Desktop\批注 2020-09-03 104022.png)

(100 + (110-10) + (120-10))/3 = 103.333....



#### 短执行时间优先STCF

当短任务到达时暂停长任务的执行，优先执行短任务，再恢复长任务的执行。

![批注 2020-09-03 104517](C:\Users\Administrator\Desktop\批注 2020-09-03 104517.png)

((120-0)+(20-10)+(30-10))/3=50

#### 响应时间

如果我们知道任务的长度以及任务只使用cpu，那么唯一的指标就是周转时间，STCF会是理想的调度策略。

响应时间是任务第一次被调度的时间减去任务到达的时间的时间差值。

![批注 2020-09-03 105341](C:\Users\Administrator\Desktop\批注 2020-09-03 105341.png)

假如A任务在0s到达，B和C任务在5s到达，那么对于A、B任务的响应时间就是0，C的响应是10，平均响应时间就是3.33。对于STCP和其相关的协议对于响应时间不是太友好，但对周转时间友好。

#### 轮询

轮询以时间片运行任务直到任务运行结束，需要注意的是时间片长度需要是时间中断长度的整数倍![批注 2020-09-03 112918](C:\Users\Administrator\Desktop\批注 2020-09-03 112918.png)

响应时间：（0+1+2）/3 = 1

轮询对响应时间友好，但是对周转时间不友好。



#### 合并IO

假设有两个任务A、B，A和B都需要CPU上运行50s，但是A运行10s后就会请求IO10s，而B只在CPU上运行。

![批注 2020-09-03 135412](C:\Users\Administrator\Desktop\批注 2020-09-03 135412.png)

在STCF中这样会造成资源的浪费。

一个通用的方法是将A视作独立的片段，当系统启动时，需要在10s的A子片段和50s的B中进行选择，根据STCF，选择10s的A，然后运行50s的B，待到A的IO执行完后，就会抢占B然后运行10s，然后继续B的运行。

![批注 2020-09-03 140049](C:\Users\Administrator\Desktop\批注 2020-09-03 140049.png)

## 多级反馈队列MLFQ

#### 基本规则

MLFQ中包含许多不同的队列，每一个队列都被赋予了不同的优先级。在每一个给定的时间里，MLFQ选择优先级高的任务去运行。当有多个优先级相同的任务需要在同一时刻去运行时，MLFQ采用轮询的方式去运行。

- 当A任务优先级大于B任务优先级时，运行A任务
- 当A任务优先级等于B任务优先级时，A和B以轮询的方式运行

MLFQ的关键在于调度器如何设置优先级。MLFQ并不给任务固定的优先级，而是根据任务的行为改变任务的优先级。例如：如果一个任务在等待键盘输入时反复放弃CPU，那么MLFQ会提高它的优先级，这就保证了交互任务的实时性。如果一个任务长时间密集地使用CPU一段时间，那么MLFQ会降低它的优先级。通过这样的方法，MLFQ就会根据任务的执行历史去判断任务的未来行为。



![批注 2020-09-03 150905](C:\Users\Administrator\Desktop\批注 2020-09-03 150905.png)

#### 如何改变优先级

假如有许多交互式短任务（可能会经常放弃CPU，等待IO）以及一些CPU密集的长任务（但是对响应时间不重视）。那么策略如下：

- 当一个新任务加入，将被存放在优先级最高的队列。
- 当一个任务将时间片中时间完全使用完，那么其优先级将被降低。
- 如果一个任务在时间片用完之前放弃CPU，那么其优先级不变。

#### 例子：单个长任务

任务刚开始被放入最高优先级队列Q2，当其用完整个时间片后优先级降低被放到Q1，当其再用完整个时间片后优先级再次降低到最低优先级队列Q0。

![批注 2020-09-03 152559](C:\Users\Administrator\Desktop\批注 2020-09-03 152559.png)

#### 补充

首先，如果有太多的交互性任务在系统中，那么长任务将会一直挨饿得不到CPU。

再次，当用户编码中有意编写代码在时间片快要用完时提出IO操作放弃CPU，那么这就能让任务持续保存在高优先级队列中，这样的话，这个任务就能几乎垄断CPU

#### 优先级提升

在经过给定时间段S后，将系统中所有任务都移到优先级最高队列里去。

